{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a TF Lite model with RETVec\n",
    "\n",
    "Please note that using RETVec with TF Lite requires `tensorflow_text>=2.13.0` and `tensorflow>=2.13.0`. You can upgrade your TensorFlow following the instructions [here](https://www.tensorflow.org/install/pip).\n",
    "\n",
    "This notebook shows how to create, save, and run a TF Lite compatible model which uses the RETVec tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing retvec if needed\n",
    "try:\n",
    "    import retvec\n",
    "except ImportError:\n",
    "    !pip install retvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 17:31:09.576542: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-10-10 17:31:09.632125: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-10 17:31:09.632160: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-10 17:31:09.632199: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-10 17:31:09.650379: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  # silence TF INFO messages\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# import the RETVec tokenizer layer\n",
    "from retvec.tf import RETVecTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only important change to make for RETVec is to set `use_native_tf_ops=True`.\n",
    "This will make the layer use `tensorflow_text.utf8_binarize` which is supported natively by TF Lite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 17:31:20.330676: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 1)]               0         \n",
      "                                                                 \n",
      " ret_vec_tokenizer (RETVecT  (None, 128, 256)          230144    \n",
      " okenizer)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 230144 (899.00 KB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 230144 (899.00 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# using strings directly requires to put a shape of (1,) and dtype tf.string\n",
    "inputs = layers.Input(shape=(1, ), name=\"input\", dtype=tf.string)\n",
    "\n",
    "# add RETVec tokenizer layer with `use_native_tf_ops`\n",
    "x = RETVecTokenizer(model='retvec-v1', use_native_tf_ops=True)(inputs)\n",
    "\n",
    "# standard two layer LSTM\n",
    "# x = layers.Bidirectional(layers.LSTM(32, return_sequences=True))(x)\n",
    "# x = layers.Bidirectional(layers.LSTM(32))(x)\n",
    "# outputs = layers.Dense(4, activation='sigmoid')(x)\n",
    "model = tf.keras.Model(inputs, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.dropout.Dropout object at 0x7fbc990be560>, because it is not built.\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.regularization.spatial_dropout1d.SpatialDropout1D object at 0x7fbc97f36b30>, because it is not built.\n",
      "INFO:tensorflow:Assets written to: ./demo_models/tflite/retvec_demo_model_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./demo_models/tflite/retvec_demo_model_2/assets\n"
     ]
    }
   ],
   "source": [
    "save_path = \"./demo_models/tflite/retvec_demo_model_2\"\n",
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-10 17:31:31.219307: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-10-10 17:31:31.219341: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-10-10 17:31:31.220140: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: ./demo_models/tflite/retvec_demo_model_2\n",
      "2023-10-10 17:31:31.224928: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-10-10 17:31:31.224945: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: ./demo_models/tflite/retvec_demo_model_2\n",
      "2023-10-10 17:31:31.250505: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:382] MLIR V1 optimization pass is not enabled\n",
      "2023-10-10 17:31:31.254321: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-10-10 17:31:31.339505: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: ./demo_models/tflite/retvec_demo_model_2\n",
      "2023-10-10 17:31:31.379132: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 158992 microseconds.\n",
      "2023-10-10 17:31:31.432961: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-10-10 17:31:31.584298: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2189] The following operation(s) need TFLite custom op implementation(s):\n",
      "Custom ops: RaggedTensorToTensor, TFText>Utf8Binarize, TFText>WhitespaceTokenizeWithOffsetsV2\n",
      "Details:\n",
      "\ttf.RaggedTensorToTensor(tensor<3xi64>, tensor<?x!tf_type.string>, tensor<!tf_type.string>, tensor<?xi64>, tensor<?xi64>) -> (tensor<?x1x128x!tf_type.string>) : {T = !tf_type.string, Tindex = i64, Tshape = i64, device = \"\", num_row_partition_tensors = 2 : i64, row_partition_types = [\"ROW_SPLITS\", \"ROW_SPLITS\"]}\n",
      "\ttf.TFText>Utf8Binarize(tensor<?x!tf_type.string>) -> (tensor<?x384xf32>) : {bits_per_char = 24 : i64, device = \"\", replacement_char = 65533 : i64, word_length = 16 : i64}\n",
      "\ttf.TFText>WhitespaceTokenizeWithOffsetsV2(tensor<?x!tf_type.string>, tensor<!tf_type.string>) -> (tensor<?x!tf_type.string>, tensor<?xi64>, tensor<?xi32>, tensor<?xi32>) : {device = \"\"}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_custom\n"
     ]
    }
   ],
   "source": [
    "# Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(save_path) # path to the SavedModel directory\n",
    "converter.target_spec.supported_ops = [\n",
    "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
    "  # tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
    "]\n",
    "converter.allow_custom_ops = True\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.lite.python import interpreter\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "interp = interpreter.InterpreterWithCustomOps(\n",
    "    model_content=tflite_model,\n",
    "    custom_op_registerers=tf_text.tflite_registrar.SELECT_TFTEXT_OPS)\n",
    "interp.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array(['Some minds are better kept apart'])\n",
    "\n",
    "tokenize = interp.get_signature_runner('serving_default')\n",
    "output = tokenize(input=input_data)\n",
    "print('TensorFlow Lite result = ', output['ret_vec_tokenizer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### isolate issue to RaggedTensorToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import app\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "\n",
    "from tensorflow.lite.python import interpreter\n",
    "\n",
    "class TokenizerModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.tokenizer = tf_text.WhitespaceTokenizer()\n",
    "\n",
    "  @tf.function(input_signature=[\n",
    "      tf.TensorSpec(shape=[None], dtype=tf.string, name='input')\n",
    "  ])\n",
    "  def call(self, input_tensor):\n",
    "    # tokens = tf_text.pad_along_dimension(self.tokenizer.tokenize(input_tensor), right_pad=[\"test\"])\n",
    "    # tokens = tf_text.pad_along_dimension(tf.ragged.constant([[\"test\"], [\"another\", \"test\"]]), right_pad=[\"test\"])\n",
    "    # tokens = tf.concat([tokens, tf.ragged.constant([['test'], ['test']])], axis=1)\n",
    "    # tokens = tokens[:,:1]\n",
    "    # tokens = self.tokenizer.tokenize(input_tensor)\n",
    "    # tokens = tokens.to_tensor()\n",
    "    # tokens = tf.reshape(tokens, (2, 1))\n",
    "    return { \n",
    "      'tokens': self.tokenizer.tokenize(input_tensor).to_tensor(default_value=\"\")\n",
    "     } # to_tensor does not work, gives a tf.Range error so this is hacky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow result =  tf.Tensor(\n",
      "[[b'Some' b'minds' b'are' b'better' b'kept' b'apart']\n",
      " [b'this' b'is' b'a' b'test' b'' b'']], shape=(2, 6), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Test input data.\n",
    "input_data = np.array(['Some minds are better kept apart', 'this is a test'])\n",
    "\n",
    "# Define a Keras model.\n",
    "model = TokenizerModel()\n",
    "\n",
    "# Perform TensorFlow Text inference.\n",
    "tf_result = model(tf.constant(input_data))\n",
    "print('TensorFlow result = ', tf_result['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe_6ldzfc/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpe_6ldzfc/assets\n",
      "2023-10-07 00:03:26.661546: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2023-10-07 00:03:26.661576: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2023-10-07 00:03:26.661808: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpe_6ldzfc\n",
      "2023-10-07 00:03:26.664423: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2023-10-07 00:03:26.664440: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpe_6ldzfc\n",
      "2023-10-07 00:03:26.677327: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2023-10-07 00:03:26.702668: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpe_6ldzfc\n",
      "2023-10-07 00:03:26.724896: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 63088 microseconds.\n",
      "2023-10-07 00:03:26.872570: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2062] The following operation(s) need TFLite custom op implementation(s):\n",
      "Custom ops: RaggedTensorToTensor, TFText>WhitespaceTokenizeWithOffsetsV2\n",
      "Details:\n",
      "\ttf.RaggedTensorToTensor(tensor<i64>, tensor<?x!tf_type.string>, tensor<!tf_type.string>, tensor<?xi64>) -> (tensor<?x?x!tf_type.string>) : {T = !tf_type.string, Tindex = i64, Tshape = i64, device = \"\", num_row_partition_tensors = 1 : i64, row_partition_types = [\"ROW_SPLITS\"]}\n",
      "\ttf.TFText>WhitespaceTokenizeWithOffsetsV2(tensor<?x!tf_type.string>, tensor<!tf_type.string>) -> (tensor<?x!tf_type.string>, tensor<?xi64>, tensor<?xi32>, tensor<?xi32>) : {device = \"\"}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_custom\n",
      "2023-10-07 00:03:26.872609: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2116] Estimated count of arithmetic ops: 0  ops, equivalently 0  MACs\n"
     ]
    }
   ],
   "source": [
    "# Convert to TensorFlow Lite.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "converter.allow_custom_ops = True\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'serving_default': {'inputs': ['input'], 'outputs': ['tokens']}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform TensorFlow Lite inference.\n",
    "interp = interpreter.InterpreterWithCustomOps(\n",
    "    model_content=tflite_model,\n",
    "    custom_op_registerers=tf_text.tflite_registrar.SELECT_TFTEXT_OPS)\n",
    "interp.get_signature_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = interp.get_signature_runner('serving_default')\n",
    "output = tokenize(input=input_data)\n",
    "print('TensorFlow Lite result = ', output['tokens'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
